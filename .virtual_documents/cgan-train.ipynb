import pandas as pd
import numpy as np
from tqdm import tqdm
import os

def load_portfolio_returns(ticker_file, data_path, valid_ratio=0.8):
    tickers = pd.read_csv(ticker_file)['ticker'].tolist()
    price_data = {}

    for ticker in tqdm(tickers, desc="ðŸ“¥ Loading price data"):
        df = pd.read_csv(f"{data_path}/{ticker}.csv", parse_dates=['date'], index_col='date')
        price_data[ticker] = df['close']

    df_prices = pd.concat(price_data, axis=1)
    df_prices = df_prices[df_prices.count(axis=1) >= int(valid_ratio * len(df_prices.columns))]
    df_prices = df_prices.ffill().bfill()
    log_returns = np.log(df_prices / df_prices.shift(1)).dropna()

    weights = np.array([1 / len(log_returns.columns)] * len(log_returns.columns))
    portfolio_returns = log_returns.dot(weights)

    return portfolio_returns

portfolio_returns = load_portfolio_returns('nasdaq_tickers.csv', 'stock_data/eod')
print(f"âœ… Loaded {len(portfolio_returns)} return days")



def create_cgan_dataset(returns, condition_window=250, prediction_horizon=250):
    X, y = [], []
    for i in tqdm(range(condition_window, len(returns) - prediction_horizon), desc="ðŸ§¹ Creating dataset"):
        X.append(returns[i - condition_window:i].values)
        y.append(returns[i:i + prediction_horizon].values)
    return np.array(X), np.array(y)

condition_window = 250
prediction_horizon = 250

X, y = create_cgan_dataset(portfolio_returns, condition_window, prediction_horizon)
print(f"âœ… Dataset created: {X.shape[0]} samples of shape ({X.shape[1]}, {y.shape[1]})")



import torch
import torch.nn as nn

class Generator(nn.Module):
    def __init__(self, noise_dim, condition_dim, output_dim):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(noise_dim + condition_dim, 128),
            nn.ReLU(),
            nn.Linear(128, output_dim)
        )
    def forward(self, noise, condition):
        x = torch.cat([noise, condition], dim=1)
        return self.model(x)

class Discriminator(nn.Module):
    def __init__(self, condition_dim, input_dim):
        super().__init__()
        self.model = nn.Sequential(
            nn.Linear(condition_dim + input_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 1),
            nn.Sigmoid()
        )
    def forward(self, sample, condition):
        x = torch.cat([sample, condition], dim=1)
        return self.model(x)



from torch.utils.data import TensorDataset, DataLoader
from tqdm.notebook import tqdm

# === Training config ===
noise_dim = 32
batch_size = 128
epochs = 1000
device = 'cuda' if torch.cuda.is_available() else 'cpu'

X_tensor = torch.tensor(X, dtype=torch.float32)
y_tensor = torch.tensor(y, dtype=torch.float32)
dataset = TensorDataset(X_tensor, y_tensor)
dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

G = Generator(noise_dim, condition_window, prediction_horizon).to(device)
D = Discriminator(condition_window, prediction_horizon).to(device)

loss_fn = nn.BCELoss()
opt_G = torch.optim.Adam(G.parameters(), lr=1e-4)
opt_D = torch.optim.Adam(D.parameters(), lr=1e-4)

# === Training loop ===
for epoch in tqdm(range(epochs), desc="ðŸŽ¯ Training"):
    for cond, real in dataloader:
        cond, real = cond.to(device), real.to(device)
        b = cond.size(0)

        # Train D
        noise = torch.randn(b, noise_dim).to(device)
        fake = G(noise, cond).detach()
        loss_D = loss_fn(D(real, cond), torch.ones_like(D(real, cond))) + \
                 loss_fn(D(fake, cond), torch.zeros_like(D(fake, cond)))
        opt_D.zero_grad()
        loss_D.backward()
        opt_D.step()

        # Train G
        noise = torch.randn(b, noise_dim).to(device)
        fake = G(noise, cond)
        loss_G = loss_fn(D(fake, cond), torch.ones_like(D(fake, cond)))
        opt_G.zero_grad()
        loss_G.backward()
        opt_G.step()

    if epoch % 10 == 0:
        print(f"Epoch {epoch}: D Loss = {loss_D.item():.4f}, G Loss = {loss_G.item():.4f}")

# === Save the model ===
save_path = "models/cgan/generic"
os.makedirs(save_path, exist_ok=True)
torch.save(G.state_dict(), f"{save_path}/generator.pth")
torch.save(D.state_dict(), f"{save_path}/discriminator.pth")
print(f"âœ… Model saved to {save_path}")




