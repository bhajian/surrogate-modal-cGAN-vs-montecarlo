{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93106e5f-24f1-4596-80b2-efb1e4372c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading price data: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 417.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 1256 return days\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def load_portfolio_returns(ticker_file, data_path, valid_ratio=0.8):\n",
    "    tickers = pd.read_csv(ticker_file)['ticker'].tolist()\n",
    "    price_data = {}\n",
    "\n",
    "    for ticker in tqdm(tickers, desc=\"ðŸ“¥ Loading price data\"):\n",
    "        df = pd.read_csv(f\"{data_path}/{ticker}.csv\", parse_dates=['date'], index_col='date')\n",
    "        price_data[ticker] = df['close']\n",
    "\n",
    "    df_prices = pd.concat(price_data, axis=1)\n",
    "    df_prices = df_prices[df_prices.count(axis=1) >= int(valid_ratio * len(df_prices.columns))]\n",
    "    df_prices = df_prices.ffill().bfill()\n",
    "    log_returns = np.log(df_prices / df_prices.shift(1)).dropna()\n",
    "\n",
    "    weights = np.array([1 / len(log_returns.columns)] * len(log_returns.columns))\n",
    "    portfolio_returns = log_returns.dot(weights)\n",
    "\n",
    "    return portfolio_returns\n",
    "\n",
    "portfolio_returns = load_portfolio_returns('nasdaq_tickers.csv', 'stock_data/eod')\n",
    "print(f\"âœ… Loaded {len(portfolio_returns)} return days\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a7f6207-5658-4121-8fe8-e6fb01a6a37f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Creating dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 756/756 [00:00<00:00, 27265.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset created: 756 samples of shape (250, 250)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def create_cgan_dataset(returns, condition_window=250, prediction_horizon=250):\n",
    "    X, y = [], []\n",
    "    for i in tqdm(range(condition_window, len(returns) - prediction_horizon), desc=\"ðŸ§¹ Creating dataset\"):\n",
    "        X.append(returns[i - condition_window:i].values)\n",
    "        y.append(returns[i:i + prediction_horizon].values)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "condition_window = 250\n",
    "prediction_horizon = 250\n",
    "\n",
    "X, y = create_cgan_dataset(portfolio_returns, condition_window, prediction_horizon)\n",
    "print(f\"âœ… Dataset created: {X.shape[0]} samples of shape ({X.shape[1]}, {y.shape[1]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b6326c-a5ee-4848-aa94-889be87d5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, noise_dim, condition_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(noise_dim + condition_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim)\n",
    "        )\n",
    "    def forward(self, noise, condition):\n",
    "        x = torch.cat([noise, condition], dim=1)\n",
    "        return self.model(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, condition_dim, input_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(condition_dim + input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, sample, condition):\n",
    "        x = torch.cat([sample, condition], dim=1)\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "363446c8-1c75-4c98-aa49-8ef1a48e22e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af2a7e3d0c14b5a94224073cbd5db75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ðŸŽ¯ Training:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: D Loss = 1.3843, G Loss = 0.6853\n",
      "Epoch 10: D Loss = 1.3619, G Loss = 0.7048\n",
      "Epoch 20: D Loss = 1.3887, G Loss = 0.6748\n",
      "Epoch 30: D Loss = 1.3772, G Loss = 0.6858\n",
      "Epoch 40: D Loss = 1.3584, G Loss = 0.7042\n",
      "Epoch 50: D Loss = 1.3710, G Loss = 0.6917\n",
      "Epoch 60: D Loss = 1.3552, G Loss = 0.7082\n",
      "Epoch 70: D Loss = 1.3693, G Loss = 0.6993\n",
      "Epoch 80: D Loss = 1.3719, G Loss = 0.6965\n",
      "Epoch 90: D Loss = 1.3670, G Loss = 0.7050\n",
      "Epoch 100: D Loss = 1.3751, G Loss = 0.6990\n",
      "Epoch 110: D Loss = 1.3671, G Loss = 0.7086\n",
      "Epoch 120: D Loss = 1.3742, G Loss = 0.6997\n",
      "Epoch 130: D Loss = 1.3721, G Loss = 0.7006\n",
      "Epoch 140: D Loss = 1.3722, G Loss = 0.7002\n",
      "Epoch 150: D Loss = 1.3767, G Loss = 0.6970\n",
      "Epoch 160: D Loss = 1.3710, G Loss = 0.7030\n",
      "Epoch 170: D Loss = 1.3785, G Loss = 0.6956\n",
      "Epoch 180: D Loss = 1.3743, G Loss = 0.7009\n",
      "Epoch 190: D Loss = 1.3761, G Loss = 0.6992\n",
      "Epoch 200: D Loss = 1.3786, G Loss = 0.6973\n",
      "Epoch 210: D Loss = 1.3772, G Loss = 0.7001\n",
      "Epoch 220: D Loss = 1.3755, G Loss = 0.7015\n",
      "Epoch 230: D Loss = 1.3797, G Loss = 0.6952\n",
      "Epoch 240: D Loss = 1.3747, G Loss = 0.7007\n",
      "Epoch 250: D Loss = 1.3829, G Loss = 0.6928\n",
      "Epoch 260: D Loss = 1.3765, G Loss = 0.6989\n",
      "Epoch 270: D Loss = 1.3819, G Loss = 0.6952\n",
      "Epoch 280: D Loss = 1.3838, G Loss = 0.6935\n",
      "Epoch 290: D Loss = 1.3861, G Loss = 0.6918\n",
      "Epoch 300: D Loss = 1.3817, G Loss = 0.6978\n",
      "Epoch 310: D Loss = 1.3830, G Loss = 0.6970\n",
      "Epoch 320: D Loss = 1.3864, G Loss = 0.6925\n",
      "Epoch 330: D Loss = 1.3847, G Loss = 0.6937\n",
      "Epoch 340: D Loss = 1.3841, G Loss = 0.6944\n",
      "Epoch 350: D Loss = 1.3862, G Loss = 0.6940\n",
      "Epoch 360: D Loss = 1.3864, G Loss = 0.6937\n",
      "Epoch 370: D Loss = 1.3853, G Loss = 0.6943\n",
      "Epoch 380: D Loss = 1.3878, G Loss = 0.6920\n",
      "Epoch 390: D Loss = 1.3855, G Loss = 0.6938\n",
      "Epoch 400: D Loss = 1.3865, G Loss = 0.6919\n",
      "Epoch 410: D Loss = 1.3858, G Loss = 0.6928\n",
      "Epoch 420: D Loss = 1.3873, G Loss = 0.6923\n",
      "Epoch 430: D Loss = 1.3865, G Loss = 0.6933\n",
      "Epoch 440: D Loss = 1.3861, G Loss = 0.6943\n",
      "Epoch 450: D Loss = 1.3861, G Loss = 0.6941\n",
      "Epoch 460: D Loss = 1.3859, G Loss = 0.6941\n",
      "Epoch 470: D Loss = 1.3867, G Loss = 0.6929\n",
      "Epoch 480: D Loss = 1.3865, G Loss = 0.6928\n",
      "Epoch 490: D Loss = 1.3853, G Loss = 0.6935\n",
      "Epoch 500: D Loss = 1.3850, G Loss = 0.6942\n",
      "Epoch 510: D Loss = 1.3867, G Loss = 0.6925\n",
      "Epoch 520: D Loss = 1.3859, G Loss = 0.6939\n",
      "Epoch 530: D Loss = 1.3858, G Loss = 0.6939\n",
      "Epoch 540: D Loss = 1.3861, G Loss = 0.6934\n",
      "Epoch 550: D Loss = 1.3855, G Loss = 0.6938\n",
      "Epoch 560: D Loss = 1.3845, G Loss = 0.6946\n",
      "Epoch 570: D Loss = 1.3868, G Loss = 0.6928\n",
      "Epoch 580: D Loss = 1.3859, G Loss = 0.6933\n",
      "Epoch 590: D Loss = 1.3849, G Loss = 0.6939\n",
      "Epoch 600: D Loss = 1.3855, G Loss = 0.6926\n",
      "Epoch 610: D Loss = 1.3853, G Loss = 0.6935\n",
      "Epoch 620: D Loss = 1.3858, G Loss = 0.6936\n",
      "Epoch 630: D Loss = 1.3840, G Loss = 0.6962\n",
      "Epoch 640: D Loss = 1.3863, G Loss = 0.6937\n",
      "Epoch 650: D Loss = 1.3844, G Loss = 0.6954\n",
      "Epoch 660: D Loss = 1.3862, G Loss = 0.6929\n",
      "Epoch 670: D Loss = 1.3847, G Loss = 0.6946\n",
      "Epoch 680: D Loss = 1.3858, G Loss = 0.6937\n",
      "Epoch 690: D Loss = 1.3842, G Loss = 0.6952\n",
      "Epoch 700: D Loss = 1.3847, G Loss = 0.6937\n",
      "Epoch 710: D Loss = 1.3853, G Loss = 0.6935\n",
      "Epoch 720: D Loss = 1.3841, G Loss = 0.6962\n",
      "Epoch 730: D Loss = 1.3839, G Loss = 0.6950\n",
      "Epoch 740: D Loss = 1.3859, G Loss = 0.6935\n",
      "Epoch 750: D Loss = 1.3848, G Loss = 0.6946\n",
      "Epoch 760: D Loss = 1.3828, G Loss = 0.6969\n",
      "Epoch 770: D Loss = 1.3840, G Loss = 0.6951\n",
      "Epoch 780: D Loss = 1.3871, G Loss = 0.6917\n",
      "Epoch 790: D Loss = 1.3833, G Loss = 0.6950\n",
      "Epoch 800: D Loss = 1.3862, G Loss = 0.6926\n",
      "Epoch 810: D Loss = 1.3851, G Loss = 0.6942\n",
      "Epoch 820: D Loss = 1.3840, G Loss = 0.6946\n",
      "Epoch 830: D Loss = 1.3858, G Loss = 0.6935\n",
      "Epoch 840: D Loss = 1.3851, G Loss = 0.6943\n",
      "Epoch 850: D Loss = 1.3842, G Loss = 0.6952\n",
      "Epoch 860: D Loss = 1.3857, G Loss = 0.6939\n",
      "Epoch 870: D Loss = 1.3844, G Loss = 0.6950\n",
      "Epoch 880: D Loss = 1.3850, G Loss = 0.6935\n",
      "Epoch 890: D Loss = 1.3844, G Loss = 0.6940\n",
      "Epoch 900: D Loss = 1.3850, G Loss = 0.6935\n",
      "Epoch 910: D Loss = 1.3839, G Loss = 0.6947\n",
      "Epoch 920: D Loss = 1.3857, G Loss = 0.6928\n",
      "Epoch 930: D Loss = 1.3850, G Loss = 0.6940\n",
      "Epoch 940: D Loss = 1.3841, G Loss = 0.6955\n",
      "Epoch 950: D Loss = 1.3845, G Loss = 0.6942\n",
      "Epoch 960: D Loss = 1.3853, G Loss = 0.6936\n",
      "Epoch 970: D Loss = 1.3853, G Loss = 0.6937\n",
      "Epoch 980: D Loss = 1.3837, G Loss = 0.6950\n",
      "Epoch 990: D Loss = 1.3845, G Loss = 0.6947\n",
      "âœ… Model saved to models/cgan/generic\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# === Training config ===\n",
    "noise_dim = 32\n",
    "batch_size = 128\n",
    "epochs = 1000\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "G = Generator(noise_dim, condition_window, prediction_horizon).to(device)\n",
    "D = Discriminator(condition_window, prediction_horizon).to(device)\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "opt_G = torch.optim.Adam(G.parameters(), lr=1e-4)\n",
    "opt_D = torch.optim.Adam(D.parameters(), lr=1e-4)\n",
    "\n",
    "# === Training loop ===\n",
    "for epoch in tqdm(range(epochs), desc=\"ðŸŽ¯ Training\"):\n",
    "    for cond, real in dataloader:\n",
    "        cond, real = cond.to(device), real.to(device)\n",
    "        b = cond.size(0)\n",
    "\n",
    "        # Train D\n",
    "        noise = torch.randn(b, noise_dim).to(device)\n",
    "        fake = G(noise, cond).detach()\n",
    "        loss_D = loss_fn(D(real, cond), torch.ones_like(D(real, cond))) + \\\n",
    "                 loss_fn(D(fake, cond), torch.zeros_like(D(fake, cond)))\n",
    "        opt_D.zero_grad()\n",
    "        loss_D.backward()\n",
    "        opt_D.step()\n",
    "\n",
    "        # Train G\n",
    "        noise = torch.randn(b, noise_dim).to(device)\n",
    "        fake = G(noise, cond)\n",
    "        loss_G = loss_fn(D(fake, cond), torch.ones_like(D(fake, cond)))\n",
    "        opt_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        opt_G.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}: D Loss = {loss_D.item():.4f}, G Loss = {loss_G.item():.4f}\")\n",
    "\n",
    "# === Save the model ===\n",
    "save_path = \"models/cgan/generic\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "torch.save(G.state_dict(), f\"{save_path}/generator.pth\")\n",
    "torch.save(D.state_dict(), f\"{save_path}/discriminator.pth\")\n",
    "print(f\"âœ… Model saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646664a0-151d-49a0-a498-113f5f5e69a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
